{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingdim = 10\n",
    "vocab = [char for char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ-']\n",
    "reverse_vocab = {x:y for y, x in enumerate(vocab)}\n",
    "key = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_matrix = 1 - (np.random.rand(len(vocab), embeddingdim) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(embed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "' '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-58d684d82055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: ' '"
     ]
    }
   ],
   "source": [
    "print(reverse_vocab[' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PQRSTUVWX'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encrypt(text):\n",
    "    chars = [char for char in text]\n",
    "    indxs = [(reverse_vocab[char] + key) % len(vocab) for char in chars]\n",
    "    encrypted = ''.join([vocab[idx] for idx in indxs])\n",
    "#     print(encrypted)\n",
    "    return encrypted\n",
    "    \n",
    "    \n",
    "encrypt('ABCDEFGHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 512\n",
    "msg_length = 32\n",
    "hidden_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tensor(str):\n",
    "    return torch.tensor([reverse_vocab[idx] for idx in str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(num_examples):\n",
    "    dataset = []\n",
    "    \n",
    "    for x in range(num_examples):\n",
    "        msg = ''.join([random.choice(vocab) for _ in range(msg_length)])\n",
    "        msg_enc = encrypt(msg)\n",
    "        \n",
    "        orig_idx = [reverse_vocab[char] for char in msg]\n",
    "        enc_idx = [reverse_vocab[char] for char in msg_enc]\n",
    "        \n",
    "        dataset.append([torch.tensor(enc_idx), torch.tensor(orig_idx)])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([ 9, 13, 18, 18,  4, 13,  8, 13, 15,  5, 13, 21, 22, 11, 23, 13,  6,  1,\n",
       "           0, 15,  8,  9, 19,  7, 23, 10,  9, 25,  2, 18, 10, 10]),\n",
       "  tensor([21, 25,  3,  3, 16, 25, 20, 25,  0, 17, 25,  6,  7, 23,  8, 25, 18, 13,\n",
       "          12,  0, 20, 21,  4, 19,  8, 22, 21, 10, 14,  3, 22, 22])]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = torch.nn.Embedding(len(vocab), embeddingdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_in = torch.rand(40, 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = torch.tensor([ 4, 4, 10,  2, 20, 11, 23,  9, 16,  9, 21, 12, 23, 26, 13, 19, 12,  1,\n",
    "           8, 19,  0,  2, 13, 22, 26, 26, 16, 20,  2,  1, 23, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bed = embed(torch.tensor([1,2,3]))\n",
    "bed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = torch.nn.LSTM(embeddingdim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(hidden_dim, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "softmax = torch.nn.functional.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(embed.parameters()) + list(lstm.parameters())\n",
    "                             + list(linear.parameters()), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_hidden():\n",
    "    return (torch.zeros(1, 1, hidden_dim),\n",
    "            torch.zeros(1, 1, hidden_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 0.4698\n",
      "Epoch: 1\n",
      "Loss: 0.0241\n",
      "Epoch: 2\n",
      "Loss: 0.0291\n",
      "Epoch: 3\n",
      "Loss: 0.0017\n",
      "Epoch: 4\n",
      "Loss: 0.0004\n",
      "Epoch: 5\n",
      "Loss: 0.0033\n",
      "Epoch: 6\n",
      "Loss: 0.0002\n",
      "Epoch: 7\n",
      "Loss: 0.0001\n",
      "Epoch: 8\n",
      "Loss: 0.0000\n",
      "Epoch: 9\n",
      "Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "accuracies, max_accuracy = [], 0\n",
    "for x in range(num_epochs):\n",
    "    print('Epoch: {}'.format(x))\n",
    "    for encrypted, original in create_dataset(num_examples):\n",
    "        # encrypted.size() = [64]\n",
    "        lstm_in = embed(encrypted)\n",
    "        # lstm_in.size() = [64, 5]. This is a 2D tensor, but LSTM expects \n",
    "        # a 3D tensor. So we insert a fake dimension.\n",
    "        lstm_in = lstm_in.unsqueeze(1)\n",
    "        # lstm_in.size() = [64, 1, 5]\n",
    "        # Get outputs from the LSTM.\n",
    "        lstm_out, lstm_hidden = lstm(lstm_in, zero_hidden())\n",
    "        # lstm_out.size() = [64, 1, 10]\n",
    "        # Apply the affine transform.\n",
    "        scores = linear(lstm_out)\n",
    "        # scores.size() = [64, 1, 27], but loss_fn expects a tensor\n",
    "        # of size [64, 27, 1]. So we switch the second and third dimensions.\n",
    "        scores = scores.transpose(1, 2)\n",
    "        # original.size() = [64], but original should also be a 2D tensor\n",
    "        # of size [64, 1]. So we insert a fake dimension.\n",
    "        original = original.unsqueeze(1)\n",
    "        # Calculate loss.\n",
    "        loss = loss_fn(scores, original) \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    print('Loss: {:6.4f}'.format(loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALLO\n",
      "WP--C\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    string = 'WP--C'\n",
    "    t = str_to_tensor(string)\n",
    "    embedded = embed(t)\n",
    "    embedded = embedded.unsqueeze(1)\n",
    "    lstm_out, lsfm_hidden = lstm(embedded, zero_hidden())\n",
    "    # print(lsfm_hidden)\n",
    "    scores = linear(lstm_out)\n",
    "    \n",
    "    predictions = softmax(scores, dim=2)\n",
    "    # print(predictions)\n",
    "    x, bout = predictions.max(dim=2)\n",
    "    bout = bout.squeeze(1)\n",
    "#     print(bout)\n",
    "    \n",
    "    print(''.join(vocab[idx] for idx in bout))\n",
    "    \n",
    "#     print(lstm_out)\n",
    "#     print(embedded)\n",
    "\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.86%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    matches, total = 0, 0\n",
    "    for encrypted, original in create_dataset(num_examples):\n",
    "        lstm_in = embed(encrypted)\n",
    "        lstm_in = lstm_in.unsqueeze(1)\n",
    "        lstm_out, lstm_hidden = lstm(lstm_in, zero_hidden())\n",
    "        scores = linear(lstm_out)\n",
    "        # Compute a softmax over the outputs\n",
    "        predictions = softmax(scores, dim=2)\n",
    "        # Choose the letter with the maximum probability\n",
    "        _, batch_out = predictions.max(dim=2)\n",
    "        # Remove fake dimension\n",
    "        batch_out = batch_out.squeeze(1)\n",
    "        # Calculate accuracy\n",
    "        matches += torch.eq(batch_out, original).sum().item()\n",
    "        total += torch.numel(batch_out)\n",
    "    accuracy = matches / total\n",
    "    print('Accuracy: {:4.2f}%'.format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
